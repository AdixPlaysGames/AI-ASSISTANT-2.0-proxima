{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45063854",
   "metadata": {},
   "source": [
    "# proxima\n",
    "## AI-POWERED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38509914",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70aa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- tkinter ----\n",
    "import tkinter as tk\n",
    "#from tkinter import font, Label, Tk\n",
    "#from tkinter import PhotoImage\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import threading\n",
    "#import wavio\n",
    "import re\n",
    "# ---- open ai ---- \n",
    "import openai\n",
    "import json\n",
    "import winsound\n",
    "from elevenlabslib import *\n",
    "from pydub import AudioSegment\n",
    "#from pydub.playback import play\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "#import config\n",
    "#import struct\n",
    "#import wave\n",
    "# ---- ElevenLabs ----\n",
    "import elevenlabs\n",
    "import soundfile as sf\n",
    "import ctypes as ct\n",
    "# ---- Google ----\n",
    "from googlesearch import search\n",
    "import webbrowser\n",
    "import tempfile\n",
    "import random\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# ---- API ----\n",
    "with open('apiKEYS.txt') as json_file:\n",
    "    keys_data = json.load(json_file)\n",
    "openaiKEY = keys_data[\"openaiKEY\"]\n",
    "elevenlabsKEY = keys_data[\"elevenlabsKEY\"]\n",
    "openai.api_key = openaiKEY\n",
    "elevenlabs.set_api_key(elevenlabsKEY)\n",
    "\n",
    "with open('PERSONALITIES.txt', 'r', encoding='utf-8') as file:\n",
    "    system = json.load(file)\n",
    "system = system[\"proxima\"][0]\n",
    "\n",
    "with open('GPT_Rules.txt', 'r', encoding='utf-8') as file:\n",
    "    GPT_rules = json.load(file)\n",
    "\n",
    "\n",
    "################################################################\n",
    "# ---- Actual version of gpt responses ----\n",
    "################################################################\n",
    "gpt_model = \"gpt-4-1106-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a475c",
   "metadata": {},
   "source": [
    "# Description\n",
    "## This is PROXIMA, personal AI assistant capable of doing unexceptional things, such as\n",
    "## generating images, websites, text files, responding with natural voice and browsing the internet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60263d5",
   "metadata": {},
   "source": [
    "# Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66dedb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Open the video file ----\n",
    "video_capture = cv2.VideoCapture(\"proxima_heart.mp4\")\n",
    "output_wav_path = \"output.wav\"\n",
    "voiceID = \"EXAVITQu4vr4xnSDxMaL\"\n",
    "messages = ['']\n",
    "\n",
    "################################################################\n",
    "# ---- Functions That Create Magic ----\n",
    "################################################################\n",
    "# ---- GPT4 web browser ----\n",
    "def GPT_search(query):\n",
    "    system = GPT_rules['GPT_search'][0]\n",
    "    response = openai.ChatCompletion.create(model=gpt_model, messages=[{\"role\": \"system\", \"content\": system}, \n",
    "                                                                     {\"role\": \"assistant\", \"content\": query}], \n",
    "                                            max_tokens=4000, stop=None, temperature=0.5)\n",
    "    query = response.choices[0].message.content\n",
    "    urls = []\n",
    "    for j in search(query, tld=\"co.in\", num=8, stop=8, pause=2):\n",
    "        urls.append(j)\n",
    "    source_links = {}\n",
    "    for link in urls:\n",
    "        source = link.split(\"//\")[1].split(\"/\")[0]\n",
    "        if source not in source_links:\n",
    "            source_links[source] = []\n",
    "        source_links[source].append(link)\n",
    "    selected_links = []\n",
    "    for source, links in source_links.items():\n",
    "        selected_links.append(random.choice(links))\n",
    "    selected_links = selected_links[0:3]\n",
    "    for url in selected_links:\n",
    "        webbrowser.open(url)\n",
    "        print(url)\n",
    "    \n",
    "# ---- GPT4 text file generator ----\n",
    "def GPTtextgenerator(gpt_input):\n",
    "    system = GPT_rules['GPTtextgenerator'][0]\n",
    "    response = openai.ChatCompletion.create(model=gpt_model, messages=[{\"role\": \"assistant\", \"content\": gpt_input}, \n",
    "                                                                             {\"role\": \"system\", \"content\": system}], \n",
    "                                            max_tokens=1000, stop=None, temperature=0.5)\n",
    "    response = response.choices[0].message.content\n",
    "    file_name = \"GPT4response.txt\"\n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(response)\n",
    "    os.system(\"notepad.exe \" + file_name)\n",
    "    \n",
    "# ---- Image generator ----\n",
    "def GPT_image(prompt):\n",
    "    system = GPT_rules['GPT_image'][0]\n",
    "    response = openai.ChatCompletion.create(model=gpt_model, messages=[{\"role\": \"assistant\", \"content\": prompt}, \n",
    "                                                                             {\"role\": \"system\", \"content\": system}], \n",
    "                                            max_tokens=1000, stop=None, temperature=0.5)\n",
    "    prompt = response.choices[0].message.content\n",
    "    print(prompt)\n",
    "    response = openai.Image.create(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt = prompt, \n",
    "        n=1,\n",
    "        size=\"1792x1024\",\n",
    "        quality=\"standard\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    response = requests.get(image_url)\n",
    "    image_data = BytesIO(response.content)\n",
    "    image = Image.open(image_data)\n",
    "    image.save(\"AI_GENERATED.png\")\n",
    "    image.show()\n",
    "\n",
    "# ---- web generator ----\n",
    "def GPT_web(prompt):\n",
    "    system = GPT_rules['web'][1][0]\n",
    "    response = openai.ChatCompletion.create(model=gpt_model, messages=[{\"role\": \"assistant\", \n",
    "                                                                               \"content\": prompt + system}], \n",
    "                                            max_tokens=4000, stop=None, temperature=0.58)\n",
    "    html_content = response.choices[0].message.content\n",
    "    \n",
    "    pattern = re.compile(r'<!DOCTYPE html>.*?</html>', re.DOTALL)\n",
    "    matches = pattern.search(html_content)\n",
    "    if matches:\n",
    "        html_content = matches.group(0).strip()\n",
    "    else:\n",
    "        print(\"Couldn't find matching HTML.\")\n",
    "        \n",
    "    web_engine_path = \"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe %s\"\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.html', encoding='utf-8') as temp:\n",
    "        temp.write(html_content)\n",
    "        \\\n",
    "          \n",
    "        webbrowser.get(web_engine_path).open('file://' + temp.name, new=2)\n",
    "    \n",
    "################################################################\n",
    "\n",
    "\n",
    "################################################################\n",
    "# ---- The rest of the code ----\n",
    "################################################################\n",
    "\n",
    "# ---- Generate window ----\n",
    "root = tk.Tk()\n",
    "root.attributes(\"-fullscreen\", True)\n",
    "root.title(\"proxima\")\n",
    "icon = tk.PhotoImage(file=\"proxima_logo.png\")\n",
    "root.iconphoto(False, icon)\n",
    "root.configure(bg='#000000')\n",
    "\n",
    "# ---- Calculate the desired canvas size based on video dimensions ----\n",
    "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH) - 600)\n",
    "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT) - 800)\n",
    "canvas_width = frame_width + 300\n",
    "canvas_height = frame_height + 300\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height, bg='#000000', highlightthickness=0)\n",
    "canvas.grid(row=1, column=0, columnspan=2)\n",
    "\n",
    "# ---- Caption-related variables ----\n",
    "caption_texts = [\"#7152bd\", \"#40e3a7\", \"#f7a068\", \"#7152bd\"] # colors of the dot\n",
    "current_caption_index = 0\n",
    "\n",
    "# ---- Audio-related vaiables ----\n",
    "is_recording = False\n",
    "audio_data = []\n",
    "record_thread = None\n",
    "\n",
    "# ---- Recording functions ----\n",
    "# - Start recording\n",
    "def start_recording():\n",
    "    global is_recording, audio_data\n",
    "    is_recording = True\n",
    "    audio_data = []\n",
    "    def callback(indata, frames, time, status):\n",
    "        if status:\n",
    "            print(status, flush=True)\n",
    "        audio_data.append(indata.copy())\n",
    "    with sd.InputStream(callback=callback):\n",
    "        while is_recording:\n",
    "            sd.sleep(0)\n",
    "# - Stop recording\n",
    "def stop_recording():\n",
    "    global is_recording\n",
    "    is_recording = False\n",
    "    sd.sleep(0)\n",
    "    audio_array = np.concatenate(audio_data, axis=0)\n",
    "    sf.write(\"output.wav\", audio_array, samplerate=44100)\n",
    "    \n",
    "# ---- Process message ----\n",
    "def process_system_message(system_message):\n",
    "    colon_index = system_message.find(\":\")\n",
    "    if colon_index != -1:\n",
    "        processed_message = system_message[colon_index + 1:].strip()\n",
    "        return processed_message\n",
    "    else:\n",
    "        return system_message\n",
    "\n",
    "# ---- AI audio transcription ----\n",
    "def transcribe_audio(audio):\n",
    "    global current_caption_index\n",
    "    audio_file = open(audio, \"rb\")\n",
    "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "    textForGPT = transcript['text']\n",
    "# ---- Here we choose which action should we use ----\n",
    "    check_text = textForGPT.lower()\n",
    "    function = 0\n",
    "    if any(element in check_text for element in GPT_rules[\"search\"][0]):\n",
    "        textForGPT += GPT_rules['internet'][0]\n",
    "        function = 1\n",
    "    elif any(element in check_text for element in GPT_rules[\"text\"][0]):\n",
    "        textForGPT += GPT_rules[\"text\"][1][0]\n",
    "        function = 2\n",
    "    elif any(element in check_text for element in GPT_rules[\"image\"][0]):\n",
    "        textForGPT += GPT_rules[\"image\"][1][0]\n",
    "        function = 3\n",
    "    elif any(element in check_text for element in GPT_rules[\"web\"][0]):\n",
    "        textForGPT += GPT_rules[\"web\"][2][0]\n",
    "        function = 4\n",
    "    else:\n",
    "        textForGPT = textForGPT\n",
    "    \n",
    "    ################################################################\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=gpt_model, \n",
    "        messages=[{\"role\": \"assistant\", \"content\": textForGPT}, \n",
    "                  {\"role\": \"system\", \"content\": system}], \n",
    "        max_tokens=120, \n",
    "        stop=None, \n",
    "        temperature=0.68)\n",
    "    \n",
    "    system_message = response[\"choices\"][0].message.content\n",
    "    voice = elevenlabs.Voice(\n",
    "        voice_id = voiceID,\n",
    "        settings = elevenlabs.VoiceSettings(\n",
    "            stability = 0.37,\n",
    "            similarity_boost = 0.80))\n",
    "    #system_message = process_system_message(system_message)\n",
    "    audio = elevenlabs.generate(\n",
    "        text = system_message,\n",
    "        voice = voice,\n",
    "        model='eleven_multilingual_v2')\n",
    "    audio = AudioSegment.from_file(io.BytesIO(audio), format=\"mp3\")\n",
    "    audio.export(\"output.wav\", format=\"wav\")\n",
    "    current_caption_index = 3\n",
    "    update_caption()\n",
    "    ################################################################\n",
    "    # Check what's goin' on\n",
    "    ################################################################\n",
    "    # function pass\n",
    "    if function == 1:\n",
    "        GPT_search(check_text)\n",
    "    elif function == 2:\n",
    "        GPTtextgenerator(check_text)\n",
    "    elif function == 3:\n",
    "        GPT_image(check_text)\n",
    "    elif function == 4:\n",
    "        GPT_web(check_text)\n",
    "    print(textForGPT)\n",
    "        \n",
    "\n",
    "# ---- Play AI ----\n",
    "def play_audio():\n",
    "    winsound.PlaySound(\"output.wav\", winsound.SND_FILENAME)\n",
    "# Thread to play audio by enter key\n",
    "def enter_key_pressed(event):\n",
    "    current_caption_index = 0 \n",
    "    update_caption()\n",
    "    audio_thread = threading.Thread(target=play_audio)\n",
    "    audio_thread.start()\n",
    "    \n",
    "# ---- Interaction ----\n",
    "def space_key_pressed(event):\n",
    "    global record_thread, current_caption_index\n",
    "    if not is_recording:\n",
    "        record_thread = threading.Thread(target=start_recording)\n",
    "        record_thread.start()\n",
    "        current_caption_index = 1 \n",
    "        update_caption()\n",
    "    else:\n",
    "        stop_recording()\n",
    "        current_caption_index = 2 \n",
    "        update_caption()\n",
    "        audio_thread = threading.Thread(target=transcribe_audio, args=(\"output.wav\",))\n",
    "        audio_thread.start()\n",
    "\n",
    "# ---- escape fullscreen ----\n",
    "def esc_key_pressed(event):\n",
    "    root.attributes(\"-fullscreen\", False)\n",
    "    dark_title_bar(root)\n",
    "\n",
    "# ---- Change the dot color ----\n",
    "def update_caption():\n",
    "    caption_label.config(fg=caption_texts[current_caption_index])\n",
    "    \n",
    "# ---- Add key functions to the window ---- \n",
    "root.bind(\"<space>\", space_key_pressed)\n",
    "root.bind(\"<Return>\", enter_key_pressed)\n",
    "root.bind(\"<Escape>\", esc_key_pressed)\n",
    "\n",
    "# ---- Add video ----\n",
    "def update_frame():\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:  # Video has ended, reset the video capture\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        ret, frame = video_capture.read()\n",
    "    if ret:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "        aspect_ratio = frame_width / frame_height\n",
    "        ballsize = canvas_height - 400\n",
    "        new_width = int(ballsize * aspect_ratio)\n",
    "        new_height = ballsize\n",
    "        frame = cv2.resize(frame, (new_width, new_height))\n",
    "        photo = ImageTk.PhotoImage(image=Image.fromarray(frame))\n",
    "        x = (canvas_width - frame.shape[1]) // 2\n",
    "        y = (canvas_height - frame.shape[0]) // 2 + 180\n",
    "        canvas.create_image(x, y, image=photo, anchor=tk.NW)\n",
    "        canvas.photo = photo\n",
    "    canvas.after(10, update_frame)\n",
    "update_frame()\n",
    "\n",
    "# ---- Dark title bar ----\n",
    "def dark_title_bar(window):\n",
    "    window.update()\n",
    "    DWMWA_USE_IMMERSIVE_DARK_MODE = 20\n",
    "    set_window_attribute = ct.windll.dwmapi.DwmSetWindowAttribute\n",
    "    get_parent = ct.windll.user32.GetParent\n",
    "    hwnd = get_parent(window.winfo_id())\n",
    "    rendering_policy = DWMWA_USE_IMMERSIVE_DARK_MODE\n",
    "    value = 2\n",
    "    value = ct.c_int(value)\n",
    "    set_window_attribute(hwnd, rendering_policy, ct.byref(value), ct.sizeof(value))\n",
    "dark_title_bar(root)\n",
    "\n",
    "# ---- Display captions on the canvas ----\n",
    "color = caption_texts[current_caption_index]\n",
    "caption_label = tk.Label(root, text=\"\\nl\", bg='#000000', fg=color, font=('Wingdings', 18))\n",
    "caption_label.grid(row=0, column=0, columnspan=2, sticky='n')  # Placed above the canvas\n",
    "\n",
    "\n",
    "# ---- Configure row and column weights ----\n",
    "root.grid_rowconfigure(0, weight=0)  # Prevent caption from expanding\n",
    "root.grid_rowconfigure(1, weight=1)\n",
    "root.grid_columnconfigure(0, weight=1)\n",
    "root.grid_columnconfigure(1, weight=0)\n",
    "\n",
    "# ---- Start window ----\n",
    "root.mainloop()\n",
    "\n",
    "# ---- Release the video capture and close the window on exit ----\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1776c57",
   "metadata": {},
   "source": [
    "# Kod autorstwa Adriana Zaręby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce4b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
